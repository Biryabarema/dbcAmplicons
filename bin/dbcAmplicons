#!/usr/bin/env python

# Copyright 2013, Institute for Bioninformatics and Evolutionary Studies
#
# Licensed under the Apache License, Version 2.0 (the 'License');
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an 'AS IS' BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.


######################################################################
##
## dbcAmplicons is an application which processes raw four read (2 sequence reads and 2 barcode reads) Illumina amplicon experiments.
##
######################################################################
import sys
import os
import errno
import argparse 
from subprocess import call
from multiprocessing import cpu_count
profile = False

# version 0.3.0
# initial release add support for preprocess and splitreads
# version 0.4.0
# add support for multiple input files
# version 0.5.0
# reconfigure repository and interface
# version 0.5.1
# added support for rdp classification
version_num = "v0.5.1"


def make_sure_path_exists(path):
    """
    Make the path
    """
    if path != '':
        try:
            os.makedirs(path)
        except OSError as exception:
            if exception.errno != errno.EEXIST:
                raise
#####################################################################################
## Preprocess four read raw amplicon data set
def preprocessApp(subparsers):
    """
    preprocessApp parser parameters
    """
    #
    # Parse options
    #
    preprocess_parser = subparsers.add_parser('preprocess', help = 'Preprocess four read raw amplicon data, identifying barcode and primer sequence')
    preprocess_parser.add_argument('-B', '--barcodes_file', help='file with barcodes',
                        action='store', type=str, metavar='barcodesFile', required=True)
    preprocess_parser.add_argument('-d', '--barcodediff', help='max hamming dist from barcode [default: %(default)s]',
                        type=int, dest='barcodediff', default=1)
    preprocess_parser.add_argument('-P', '--primer_file', help='file with primers',
                        action='store', type=str, dest='primer_file',metavar='primerFile', default=None)
    preprocess_parser.add_argument('-D', '--primerdiff', help='max hamming dist from primer [default: %(default)s]',
                        type=int, dest='primerdiff', default=4)
    preprocess_parser.add_argument('-e', '--primerend', help='required number of matching bases at end of primer [default: %(default)s]',
                        type=int, dest='primerend', default=4)
    preprocess_parser.add_argument('-S', '--samples_file', help='file with primers',
                        action='store', type=str, dest='samples_file',metavar='sampleFile', default=None)
    preprocess_parser.add_argument('-q', '--minQ', help="trim 3' end of sequences to minQ [default: %(default)s]",
                        type=int, dest='minQ', default=None),
    preprocess_parser.add_argument('-l', '--minL', help='if minQ is not None, only keep reads that are at least minL length [default: %(default)s]',
                        type=int, dest='minL', default=0),
    preprocess_parser.add_argument('-b', '--batchsize', help='batch size to process reads in [default: %(default)s]',
                        type=int, dest='batchsize', default=10000)    
    preprocess_parser.add_argument('-O', '--output_prefix', help='output file basename [default: fastq_prefix]',
                        action='store', type=str, dest='output_base', metavar='PREFIX', default=None)
    preprocess_parser.add_argument('-U', '--output_unidentified', help='output unidentified reads [default: %(default)s]',
                        action='store_true', dest='unidentified', default=False)
    preprocess_parser.add_argument('-u', '--uncompressed', help='leave output files uncompressed [default: %(default)s]',
                        action='store_true', dest='uncompressed', default=False)
    preprocess_parser.add_argument('-v', '--silent', help='verbose output [default: %(default)s]',
                        action='store_true', dest='verbose', default=False)
    preprocess_parser.add_argument('-1', metavar="read1", dest='fastq_file1', help='read1 of an amplicon fastq four file set',
                        action='store',type=str, required=True, nargs='+')
    preprocess_parser.add_argument('-2', metavar="read2", dest='fastq_file2', help='read2 of an amplicon fastq four file set',
                        action='store',type=str, required=True, nargs='+')
    preprocess_parser.add_argument('-3', metavar="read3", dest='fastq_file3', help='read3 of an amplicon fastq four file set',
                        action='store',type=str, required=True, nargs='+')
    preprocess_parser.add_argument('-4', metavar="read4", dest='fastq_file4', help='read4 of an amplicon fastq four file set',
                        action='store',type=str, required=True, nargs='+')
    preprocess_parser.add_argument('--debug', help='show traceback on error',
                        action='store_true', dest="debug", default = False)
    return preprocess_parser 

class preprocessCMD:
    """
    validate preprocessApp parser parameters and launch the app
    """
    def __init__(self):
        pass
    def execute (self,args):
        verbose = not args.verbose
        # ----------------------- options input files -----------------------
        bcFile = args.barcodes_file
        if args.samples_file == None:
            sFile = None
            if verbose:
                print "No sample file identified"
        else:
            sFile = args.samples_file
        if args.primer_file == None:
            prFile = None
            if verbose:
                print "No primer file identified"
        else:
            prFile = args.primer_file
        # ----------------------- options output prefix -----------------------
        if args.output_base is None and sFile is None:
            output_prefix = "preprocessed_out"
        elif args.output_base is None and sFile is not None:
            output_prefix = "."
        elif args.output_base is not None and sFile is None:
            output_prefix = args.output_base
#            make_sure_path_exists(os.path.dirname(output_prefix))
        elif args.output_base is not None and sFile is not None:
            output_prefix = args.output_base
#            make_sure_path_exists(output_prefix)

        from dbcAmplicons import preprocessApp
        app = preprocessApp()

        if profile:
            import cProfile
            cProfile.runctx('app.start(args.fastq_file1, args.fastq_file2, args.fastq_file3, args.fastq_file4, output_prefix, bcFile, prFile, sFile, args.barcodediff, args.primerdiff, args.primerend, args.batchsize, args.uncompressed, args.unidentified, args.minQ, args.minL, verbose, args.debug)', globals(), locals())
            return 255
        else:
            return app.start(args.fastq_file1, args.fastq_file2, args.fastq_file3, args.fastq_file4, output_prefix, bcFile, prFile, sFile, args.barcodediff, args.primerdiff, args.primerend, args.batchsize, args.uncompressed, args.unidentified, args.minQ, args.minL, verbose, args.debug)

#####################################################################################
## Split Preprocessed data by project
def splitreadsApp(subparsers):
    """
    splitreadsApp parser parameters
    """
    #
    # Parse options
    #
    preprocess_parser = subparsers.add_parser('splitreads', help = 'Split reads from a preprocessed four read illumina run by project id')
    preprocess_parser.add_argument('-b', '--batchsize', help='batch size to process reads in [default: %(default)s]',
                        type=int, dest='batchsize', default=10000)    
    preprocess_parser.add_argument('-O', '--output_path', help='path for output files [default: %(default)s]',
                        action='store', type=str, dest='output_base', metavar='PREFIX', default=".")
    preprocess_parser.add_argument('-U', '--output_unidentified', help='output unidentified reads [default: %(default)s]',
                        action='store_true', dest='unidentified', default=False)
    preprocess_parser.add_argument('-u', '--uncompressed', help='leave output files uncompressed [default: %(default)s]',
                        action='store_true', dest='uncompressed', default=False)
    preprocess_parser.add_argument('-v', '--silent', help='verbose output [default: %(default)s]',
                        action='store_true', dest='verbose', default=False)
    preprocess_parser.add_argument('-S', '--samples_file', help='file with primers',
                        action='store', type=str, dest='samples_file',metavar='sampleFile', default=None, required=True)
    preprocess_parser.add_argument('-1', metavar="read1", dest='fastq_file1', help='read1 of an amplicon fastq two file set',
                        action='store',type=str, required=True, nargs='+')
    preprocess_parser.add_argument('-2', metavar="read2", dest='fastq_file2', help='read2 of an amplicon fastq two file set',
                        action='store',type=str, required=True, nargs='+')
    preprocess_parser.add_argument('--debug', help='show traceback on error',
                        action='store_true', dest="debug", default = False)
    return preprocess_parser 

class splitreadsCMD:
    """
    validate splitreadsApp parser parameters and launch the app
    """
    def __init__(self):
        pass
    def execute (self,args):
        # ----------------------- options input files -----------------------
        sFile = args.samples_file
        # ----------------------- options output prefix -----------------------
        output_prefix = args.output_base
#        make_sure_path_exists(output_prefix)
#        make_sure_path_exists(os.path.dirname(output_prefix))
        uncompressed = args.uncompressed
        output_unidentified = args.unidentified
        # ----------------------- other options ------------
        debug = args.debug
        verbose = not args.verbose
        batchsize = args.batchsize

        from dbcAmplicons import splitreadsApp
        app = splitreadsApp()

        if profile:
            import cProfile
            cProfile.runctx('app.start(args.fastq_file1, args.fastq_file2, output_prefix, sFile, batchsize, uncompressed, output_unidentified, verbose, debug)', globals(), locals())
            return 255
        else:
            return app.start(args.fastq_file1, args.fastq_file2, output_prefix, sFile, batchsize, uncompressed, output_unidentified, verbose, debug)


#####################################################################################
## join reads using flash, path through application
def joinApp(subparsers):
    """
    joinApp parser parameters
    """
    #
    # Parse options
    #
    preprocess_parser = subparsers.add_parser('join', help = 'join reads using flash')
    preprocess_parser.add_argument('-O', '--output_path', help='path for output files [default: %(default)s]',
                        action='store', type=str, dest='output_base', metavar='PREFIX', default="joined")
    preprocess_parser.add_argument('-u', '--uncompressed', help='leave output files uncompressed [default: %(default)s]',
                        action='store_true', dest='uncompressed', default=False)
    preprocess_parser.add_argument('-x', '--max-mismatch-density', help=' Maximum allowed ratio between the number of \
                          mismatched base pairs and the overlap length. \
                          Two reads will not be combined with a given overlap \
                          if that overlap results in a mismatched base density \
                          higher than this value.  Note: Any occurence of an \
                          "N" in either read is ignored and not counted \
                          towards the mismatches or overlap length. [default:%(default)s]', type=float, dest='max_mixmatch_density', metavar='NUM',
                          default=0.25)
    preprocess_parser.add_argument('-t', '--threads',metavar='NTHREADS', help='Set the number of worker threads. [default: %(default)s]',
                        type=int, dest='threads',default=1)
    preprocess_parser.add_argument('-p', '--flash_path', help='path to the application flash [default: %(default)s]',
                        action='store', type=str, dest='flash_path',metavar='path', default='flash', required=False)
    preprocess_parser.add_argument('-1', metavar="read1", dest='fastq_file1', help='read1 of an amplicon fastq (or fastq.gz) two file set',
                        action='store',type=str, required=True)
    preprocess_parser.add_argument('-2', metavar="read2", dest='fastq_file2', help='read2 of an amplicon fastq (or fastq.gz)  two file set',
                        action='store',type=str, required=True)
    return preprocess_parser 

class joinCMD:
    """
    validate joinApp parser parameters and launch the app
    """
    def __init__(self):
        pass
    def execute (self,args):
        # ----------------------- options output prefix -----------------------
        output_prefix = args.output_base
        make_sure_path_exists(os.path.dirname(output_prefix))
        if args.uncompressed:
            compress=""
        else:
            compress='-z'
        # System call
        call_string = [args.flash_path,"-t",str(args.threads),"-x",str(args.max_mixmatch_density),"-o",output_prefix,compress,args.fastq_file1,args.fastq_file2]
        if profile:
            import cProfile
            cProfile.runctx('call(call_string)', globals(), locals())
            return 255
        else:
            return call(call_string)


#####################################################################################
## Classify reads using rdp
def classifyApp(subparsers):
    """
    classifyApp parser parameters
    """
    #
    # Parse options
    #
    preprocess_parser = subparsers.add_parser('classify', help = 'classify reads using RDP generating a fixrank formated file')
    preprocess_parser.add_argument('-b', '--batchsize', help='batch size to process reads in [default: %(default)s]',
                        type=int, dest='batchsize', default=10000)    
    preprocess_parser.add_argument('-p', '--processors', help='number of processors to use, [default: %(default)s]',
                        type=int, dest='procs', default=1)
    preprocess_parser.add_argument('--rdpPath',metavar='PATH', dest='rdpPath', help='path to the RDP classifier',
                        action='store',type=str, default='classify.jar', required=False)
    preprocess_parser.add_argument('-g','--gene',metavar='<arg>', dest='gene', help='16srrna or fungallsu [default: %(default)s]',
                        action='store',type=str, default='16srrna', required=False)
    preprocess_parser.add_argument('-S', '--samples_file', help='file with primers',
                        action='store', type=str, dest='samples_file',metavar='sampleFile', default=None, required=False)
    preprocess_parser.add_argument('-O', '--output_path', help='path for output files [default: %(default)s]',
                        action='store', type=str, dest='output_base', metavar='outputPrefix', default='classify')
    preprocess_parser.add_argument('-1', metavar="read1", dest='fastq_file1', help='read1 of an amplicon fastq two file set',
                        action='store',type=str, default=None, required=False, nargs='+')
    preprocess_parser.add_argument('-2', metavar="read2", dest='fastq_file2', help='read2 of an amplicon fastq two file set',
                        action='store',type=str, default=None, required=False, nargs='+')
    preprocess_parser.add_argument('-U', metavar="single", dest='fastq_file3', help='single-end amplicon, typically from joined paired reads',
                        action='store',type=str, default=None, required=False, nargs='+')
    preprocess_parser.add_argument('-v', '--silent', help='verbose output [default: %(default)s]',
                        action='store_true', dest='verbose', default=False)
    preprocess_parser.add_argument('--debug', help='show traceback on error',
                        action='store_true', dest="debug", default = False)
    return preprocess_parser 

class classifyCMD:
    """
    validate classifyApp parser parameters and launch the app
    """
    def __init__(self):
        pass
    def execute (self,args):
        # ----------------------- options input files -----------------------
        sFile = args.samples_file
        # ----------------------- options output prefix -----------------------
        output_prefix = args.output_base
        # ----------------------- other options ------------
        debug = args.debug
        verbose = not args.verbose
        batchsize = args.batchsize
        procs = args.procs
        rdpPath = args.rdpPath

        if (procs > cpu_count()):
            print("The number of processors specified [%s] is greater than the number available [%s], exiting application" % (str(procs),str(cpu_count())))
            sys.exit()

        if (args.gene != '16srrna' and args.gene != 'fungallsu'):
            print("parameter -g (--gene) must be one of 16srrna or fungallsu")
            sys.exit()

        from dbcAmplicons import classifyApp
        app = classifyApp()

        if profile:
            import cProfile
            cProfile.runctx('app.start(args.fastq_file1, args.fastq_file2, args.fastq_file3, output_prefix, rdpPath, args.gene, batchsize, procs, verbose, debug)', globals(), locals())
            return 255
        else:
            return app.start(args.fastq_file1, args.fastq_file2, args.fastq_file3, output_prefix, rdpPath, batchsize, procs, verbose, debug)

#####################################################################################
## Compute an abundance table from classified reads in fixrank format
def abundanceApp(subparsers):
    """
    abundanceApp parser parameters
    """
    #
    # Parse options
    #
    preprocess_parser = subparsers.add_parser('abundance', help = 'Generate an abundance table from a fixrank formated file')
    preprocess_parser.add_argument('-r', '--rank', help='taxonomic rank to build table from, allowable values are (domain, phylum, class, order, family, genus, and species{if performed}, [default: %(default)s]',
                        action='store', type=str, dest='rank', metavar='<arg>', default='genus', required=False, choices=['domain', 'phylum', 'class', 'order', 'family', 'genus', 'species'])
    preprocess_parser.add_argument('-t', '--threshold', help='Threshold bootstrap value to use for assignment, first taxon level greater than threshold',
                        type=float, dest='threshold', metavar="VALUE", default=0.5,required=False)
    preprocess_parser.add_argument('-S', '--samples_file', help='file with primers',
                        action='store', type=str, dest='samples_file',metavar='FILE', default=None, required=False)
    preprocess_parser.add_argument('-O', '--output_path', help='path for output files [default: %(default)s]',
                        action='store', type=str, dest='output_base', metavar='FILE_PREFIX', default='table')
    preprocess_parser.add_argument('-F', metavar="FILE", dest='fixrank_file', help='fixrank formated classification file generated by classify',
                        action='store',type=str, default=None, required=True, nargs='+')
    preprocess_parser.add_argument('-v', '--silent', help='verbose output [default: %(default)s]',
                        action='store_true', dest='verbose', default=False)
    preprocess_parser.add_argument('--debug', help='show traceback on error',
                        action='store_true', dest="debug", default = False)
    return preprocess_parser 

class abundanceCMD:
    """
    validate abundanceApp parser parameters and launch the app
    """
    def __init__(self):
        pass
    def execute (self,args):
        # ----------------------- options input files -----------------------
        sFile = args.samples_file
        # ----------------------- options output prefix -----------------------
        output_prefix = args.output_base
        # ----------------------- other options ------------
        debug = args.debug
        verbose = not args.verbose

        from dbcAmplicons import abundanceApp
        app = abundanceApp()

        if profile:
            import cProfile
            cProfile.runctx('app.start(args.fixrank_file, sFile, output_prefix, args.rank, args.threshold, verbose, debug)', globals(), locals())
            return 255
        else:
            return app.start(args.fixrank_file, sFile, output_prefix, args.rank, args.threshold, verbose, debug)


#
#####################################################################################
##  Master parser arguments
def parseArgs():
    """
    generate main parser
    """
    parser = argparse.ArgumentParser( \
        description = 'dbcAmplicons, a python package for preprocessing of massively multiplexed, dual barcoded Illumina Amplicons', \
        epilog ='For questions or comments, please contact Matt Settles <msettles@uidaho.edu>', add_help=True)
    parser.add_argument('--version', action='version', version="%(prog)s Version " + version_num)
    subparsers = parser.add_subparsers(help='commands', dest='command')

    preprocessApp(subparsers)
    splitreadsApp(subparsers)
    joinApp(subparsers)
    classifyApp(subparsers)
    abundanceApp(subparsers)

    args = parser.parse_args() 

    return args


def main():
    """
    main function
    """
    preprocess = preprocessCMD()
    splitreads = splitreadsCMD()
    join = joinCMD()
    classify = classifyCMD()
    abundance = abundanceCMD()

    commands = {'preprocess': preprocess, 'splitreads':splitreads, 'join':join, 'classify':classify, 'abundance':abundance}

    args = parseArgs()
    lib_path = os.path.join(os.path.dirname(os.path.abspath(__file__)), '../')
    if lib_path not in sys.path:
        sys.path.insert(0, lib_path)


    commands[args.command].execute(args)

if __name__ == '__main__':
    main()
 