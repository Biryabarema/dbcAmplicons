#!/usr/bin/env python

# Copyright 2013, Institute for Bioninformatics and Evolutionary Studies
#
# Licensed under the Apache License, Version 2.0 (the 'License');
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an 'AS IS' BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.


######################################################################
##
## dbcAmplicons is an application which processes raw four read (2 sequence reads and 2 barcode reads) Illumina amplicon experiments.
##
######################################################################
import sys
import os
import errno
import argparse 
from subprocess import call

profile = False

# version 0.3.0
# initial release add support for preprocess and splitreads
# version 0.4.0
# add support for multiple input files
# version 0.5.0
# reconfigure repository and interface
version_num = "v0.5.0"


def make_sure_path_exists(path):
    """
    Make the path
    """
    if path != '':
        try:
            os.makedirs(path)
        except OSError as exception:
            if exception.errno != errno.EEXIST:
                raise
#####################################################################################
## Preprocess four read raw amplicon data set
def preprocessApp(subparsers):
    """
    preprocessApp parser parameters
    """
    #
    # Parse options
    #
    preprocess_parser = subparsers.add_parser('preprocess', help = 'Preprocess four read raw amplicon data, identifying barcode and primer sequence')
    preprocess_parser.add_argument('-b', '--barcodes_file', help='file with barcodes',
                        action='store', type=str, metavar='barcodesFile', required=True, nargs=1)
    preprocess_parser.add_argument('-d', '--barcodediff', help='max hamming dist from barcode [default: %(default)s]',
                        type=int, dest='barcodediff', default=[1], nargs=1)
    preprocess_parser.add_argument('-p', '--primer_file', help='file with primers',
                        action='store', type=str, dest='primer_file',metavar='primerFile', default=None, nargs=1)
    preprocess_parser.add_argument('-D', '--primerdiff', help='max hamming dist from primer [default: %(default)s]',
                        type=int, dest='primerdiff', default=[4], nargs=1)
    preprocess_parser.add_argument('-e', '--primerend', help='required number of matching bases at end of primer [default: %(default)s]',
                        type=int, dest='primerend', default=[4], nargs=1)
    preprocess_parser.add_argument('-s', '--samples_file', help='file with primers',
                        action='store', type=str, dest='samples_file',metavar='sampleFile', default=None, nargs=1)
    preprocess_parser.add_argument('-B', '--batchsize', help='batch size to process reads in [default: %(default)s]',
                        type=int, dest='batchsize', default=[10000], nargs=1)    
    preprocess_parser.add_argument('-o', '--output_prefix', help='output file basename [default: fastq_prefix]',
                        action='store', type=str, dest='output_base', metavar='PREFIX', default=None, nargs=1)
    preprocess_parser.add_argument('-u', '--output_unidentified', help='output unidentified reads [default: %(default)s]',
                        action='store_true', dest='unidentified', default=False)
    preprocess_parser.add_argument('-U', '--uncompressed', help='leave output files uncompressed [default: %(default)s]',
                        action='store_true', dest='uncompressed', default=False)
    preprocess_parser.add_argument('-v', '--silent', help='verbose output [default: %(default)s]',
                        action='store_true', dest='verbose', default=False)
    preprocess_parser.add_argument('-1', metavar="read1", dest='fastq_file1', help='read1 of an amplicon fastq four file set',
                        action='store',type=str, required=True, nargs='+')
    preprocess_parser.add_argument('-2', metavar="read2", dest='fastq_file2', help='read2 of an amplicon fastq four file set',
                        action='store',type=str, required=True, nargs='+')
    preprocess_parser.add_argument('-3', metavar="read3", dest='fastq_file3', help='read3 of an amplicon fastq four file set',
                        action='store',type=str, required=True, nargs='+')
    preprocess_parser.add_argument('-4', metavar="read4", dest='fastq_file4', help='read4 of an amplicon fastq four file set',
                        action='store',type=str, required=True, nargs='+')
    preprocess_parser.add_argument('--debug', help='show traceback on error',
                        action='store_true', dest="debug", default = False)
    return preprocess_parser 

class preprocessCMD:
    """
    validate preprocessApp parser parameters and launch the app
    """
    def __init__(self):
        pass
    def execute (self,args):
        verbose = not args.verbose
        # ----------------------- options input files -----------------------
        bcFile = args.barcodes_file[0]
        if args.samples_file == None:
            sFile = None
            if verbose:
                print "No sample file identified"
        else:
            sFile = args.samples_file[0]
        if args.primer_file == None:
            prFile = None
            if verbose:
                print "No primer file identified"
        else:
            prFile = args.primer_file[0]
        # ----------------------- options output prefix -----------------------
        if args.output_base is None and sFile is None:
            output_prefix = "preprocessed_out"
        elif args.output_base is None and sFile is not None:
            output_prefix = "."
        elif args.output_base is not None and sFile is None:
            output_prefix = args.output_base[0]
#            make_sure_path_exists(os.path.dirname(output_prefix))
        elif args.output_base is not None and sFile is not None:
            output_prefix = args.output_base[0]
#            make_sure_path_exists(output_prefix)

        from dbcAmplicons import preprocessApp
        app = preprocessApp()

        if profile:
            import cProfile
            cProfile.runctx('app.start(args.fastq_file1, args.fastq_file2, args.fastq_file3, args.fastq_file4, output_prefix, bcFile, prFile, sFile, args.barcodediff[0], args.primerdiff[0], args.primerend[0], args.batchsize[0], args.uncompressed, args.unidentified, verbose, args.debug)', globals(), locals())
            return 255
        else:
            return app.start(args.fastq_file1, args.fastq_file2, args.fastq_file3, args.fastq_file4, output_prefix, bcFile, prFile, sFile, args.barcodediff[0], args.primerdiff[0], args.primerend[0], args.batchsize[0], args.uncompressed, args.unidentified, verbose, args.debug)

#####################################################################################
## Split Preprocessed data by project
def splitreadsApp(subparsers):
    """
    splitreadsApp parser parameters
    """
    #
    # Parse options
    #
    preprocess_parser = subparsers.add_parser('splitreads', help = 'Split reads from a preprocessed four read illumina run by project id')
    preprocess_parser.add_argument('-B', '--batchsize', help='batch size to process reads in [default: %(default)s]',
                        type=int, dest='batchsize', default=[10000], nargs=1)    
    preprocess_parser.add_argument('-o', '--output_path', help='path for output files [default: %(default)s]',
                        action='store', type=str, dest='output_base', metavar='PREFIX', default=".", nargs=1)
    preprocess_parser.add_argument('-u', '--output_unidentified', help='output unidentified reads [default: %(default)s]',
                        action='store_true', dest='unidentified', default=False)
    preprocess_parser.add_argument('-U', '--uncompressed', help='leave output files uncompressed [default: %(default)s]',
                        action='store_true', dest='uncompressed', default=False)
    preprocess_parser.add_argument('-v', '--silent', help='verbose output [default: %(default)s]',
                        action='store_true', dest='verbose', default=False)
    preprocess_parser.add_argument('-s', '--samples_file', help='file with primers',
                        action='store', type=str, dest='samples_file',metavar='sampleFile', default=None, required=True, nargs=1)
    preprocess_parser.add_argument('-1', metavar="read1", dest='fastq_file1', help='read1 of an amplicon fastq four file set',
                        action='store',type=str, required=True, nargs='+')
    preprocess_parser.add_argument('-2', metavar="read2", dest='fastq_file2', help='read2 of an amplicon fastq four file set',
                        action='store',type=str, required=True, nargs='+')
    preprocess_parser.add_argument('--debug', help='show traceback on error',
                        action='store_true', dest="debug", default = False)
    return preprocess_parser 

class splitreadsCMD:
    """
    validate splitreadsApp parser parameters and launch the app
    """
    def __init__(self):
        pass
    def execute (self,args):
        # ----------------------- options input files -----------------------
        sFile = args.samples_file[0]
        # ----------------------- options output prefix -----------------------
        output_prefix = args.output_base[0]
#        make_sure_path_exists(output_prefix)
#        make_sure_path_exists(os.path.dirname(output_prefix))
        uncompressed = args.uncompressed
        output_unidentified = args.unidentified
        # ----------------------- other options ------------
        debug = args.debug
        verbose = not args.verbose
        batchsize = args.batchsize[0]

        from dbcAmplicons import splitreadsApp
        app = splitreadsApp()

        if profile:
            import cProfile
            cProfile.runctx('app.start(args.fastq_file1, args.fastq_file2, output_prefix, sFile, batchsize, uncompressed, output_unidentified, verbose, debug)', globals(), locals())
            return 255
        else:
            return app.start(args.fastq_file1, args.fastq_file2, output_prefix, sFile, batchsize, uncompressed, output_unidentified, verbose, debug)


#####################################################################################
## join reads using flash, path through application
def joinApp(subparsers):
    """
    joinApp parser parameters
    """
    #
    # Parse options
    #
    preprocess_parser = subparsers.add_parser('join', help = 'join reads using flash')
    preprocess_parser.add_argument('-o', '--output_path', help='path for output files [default: %(default)s]',
                        action='store', type=str, dest='output_base', metavar='PREFIX', default=".", nargs=1)
    preprocess_parser.add_argument('-U', '--uncompressed', help='leave output files uncompressed [default: %(default)s]',
                        action='store_true', dest='uncompressed', default=False)
    preprocess_parser.add_argument('-x', '--max-mismatch-density', help=' Maximum allowed ratio between the number of \
                          mismatched base pairs and the overlap length. \
                          Two reads will not be combined with a given overlap \
                          if that overlap results in a mismatched base density \
                          higher than this value.  Note: Any occurence of an \
                          "N" in either read is ignored and not counted \
                          towards the mismatches or overlap length. [default:%(default)s]', type=int, dest='max_mixmatch_density', metavar='NUM',
                          default=0.25, nargs=1)
    preprocess_parser.add_argument('-t', '--threads',metavar='NTHREADS', help='Set the number of worker threads.',
                        type=int, dest='threads',default=[0.25],nargs=1)
    preprocess_parser.add_argument('-p', '--flash_path', help='path to the application flash',
                        action='store', type=str, dest='flash_path',metavar='path', default='flash', required=False, nargs=1)
    preprocess_parser.add_argument('-1', metavar="read1", dest='fastq_file1', help='read1 of an amplicon fastq four file set',
                        action='store',type=str, required=True, nargs='+')
    preprocess_parser.add_argument('-2', metavar="read2", dest='fastq_file2', help='read2 of an amplicon fastq four file set',
                        action='store',type=str, required=True, nargs='+')
    return preprocess_parser 

class joinCMD:
    """
    validate joinApp parser parameters and launch the app
    """
    def __init__(self):
        pass
    def execute (self,args):
        # ----------------------- options output prefix -----------------------
        output_prefix = args.output_base[0]

        if args.uncompressed:
            compress=""
        else:
            compress='-z'
        # System call
        call_string = " ".join([args.flash_path,"-t",args.threads,"-x",args.max_mixmatch_density,"-o",output_prefix,compress,args.fastq_file1,args.fastq_file2])
        if profile:
            import cProfile
            cProfile.runctx('subprocess.call(call_string)', globals(), locals())
            return 255
        else:
            return call(call_string)


#####################################################################################
## Classify reads using rdp
def classifyApp(subparsers):
    """
    classifyApp parser parameters
    """
    #
    # Parse options
    #
    preprocess_parser = subparsers.add_parser('classify', help = 'classify reads using RDP')
    preprocess_parser.add_argument('-B', '--batchsize', help='batch size to process reads in [default: %(default)s]',
                        type=int, dest='batchsize', default=[10000], nargs=1)    
    preprocess_parser.add_argument('-o', '--output_path', help='path for output files [default: %(default)s]',
                        action='store', type=str, dest='output_base', metavar='outputPrefix', default=".", nargs=1)
    preprocess_parser.add_argument('-u', '--output_unidentified', help='output unidentified reads [default: %(default)s]',
                        action='store_true', dest='unidentified', default=False)
    preprocess_parser.add_argument('-v', '--silent', help='verbose output [default: %(default)s]',
                        action='store_true', dest='verbose', default=False)
    preprocess_parser.add_argument('-s', '--samples_file', help='file with primers',
                        action='store', type=str, dest='samples_file',metavar='sampleFile', default=None, required=True, nargs=1)
    preprocess_parser.add_argument('-1', metavar="read1", dest='fastq_file1', help='read1 of an amplicon fastq four file set',
                        action='store',type=str, required=False, nargs='+')
    preprocess_parser.add_argument('-2', metavar="read2", dest='fastq_file2', help='read2 of an amplicon fastq four file set',
                        action='store',type=str, required=False, nargs='+')
    preprocess_parser.add_argument('-U', metavar="single", dest='fastq_file3', help='single-end amplicon, typically from joined paired reads',
                        action='store',type=str, required=False, nargs='+')
    preprocess_parser.add_argument('--debug', help='show traceback on error',
                        action='store_true', dest="debug", default = False)
    return preprocess_parser 

class classifyCMD:
    """
    validate classifyApp parser parameters and launch the app
    """
    def __init__(self):
        pass
    def execute (self,args):
        # ----------------------- options input files -----------------------
        sFile = args.samples_file[0]
        # ----------------------- options output prefix -----------------------
        output_prefix = args.output_base[0]
#        make_sure_path_exists(output_prefix)
#        make_sure_path_exists(os.path.dirname(output_prefix))
        output_unidentified = args.unidentified
        # ----------------------- other options ------------
        debug = args.debug
        verbose = not args.verbose
        batchsize = args.batchsize[0]

        from dbcAmplicons import classifyApp
        app = classifyApp()

        if profile:
            import cProfile
            cProfile.runctx('app.start(args.fastq_file1, args.fastq_file2, args.fastq_file3, output_prefix, sFile, batchsize, output_unidentified, verbose, debug)', globals(), locals())
            return 255
        else:
            return app.start(args.fastq_file1, args.fastq_file2, args.fastq_file3, output_prefix, sFile, batchsize, output_unidentified, verbose, debug)

#
#####################################################################################
##  Master parser arguments
def parseArgs():
    """
    generate main parser
    """
    parser = argparse.ArgumentParser( \
        description = 'dbcAmplicons, a python package for preprocessing of massively multiplexed, dual barcoded Illumina Amplicons', \
        epilog ='For questions or comments, please contact Matt Settles <msettles@uidaho.edu>', add_help=True)
    parser.add_argument('--version', action='version', version="%(prog)s Version " + version_num)
    subparsers = parser.add_subparsers(help='commands', dest='command')

    preprocessApp(subparsers)
    splitreadsApp(subparsers)
    joinApp(subparsers)

    args = parser.parse_args() 

    return args


def main():
    """
    main function
    """
    preprocess = preprocessCMD()
    splitreads = splitreadsCMD()
    join = joinCMD()

    commands = {'preprocess': preprocess, 'splitreads':splitreads, 'join':join}

    args = parseArgs()
    lib_path = os.path.join(os.path.dirname(os.path.abspath(__file__)), '../')
    if lib_path not in sys.path:
        sys.path.insert(0, lib_path)


    commands[args.command].execute(args)

if __name__ == '__main__':
    main()
